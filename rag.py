import os
import sys
import logging

# Loglama yapÄ±landÄ±rmasÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Gerekli paketleri kontrol et
try:
    from huggingface_hub import hf_hub_download
    from langchain_community.document_loaders import PyPDFLoader
    try:
        from langchain_text_splitters import RecursiveCharacterTextSplitter
    except ImportError:
        from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.llms import LlamaCpp
    from langchain.chains import RetrievalQA
    from langchain.prompts import PromptTemplate
except ImportError as e:
    logger.error(f"Gerekli paket eksik: {e}")
    logger.error("LÃ¼tfen ÅŸunu Ã§alÄ±ÅŸtÄ±rÄ±n: pip install langchain langchain-community pypdf chromadb sentence-transformers llama-cpp-python huggingface_hub")
    sys.exit(1)

# YapÄ±landÄ±rma
MODEL_REPO = "microsoft/Phi-3-mini-4k-instruct-gguf"
MODEL_FILENAME = "Phi-3-mini-4k-instruct-q4.gguf"
MODEL_DIR = "models"
MODEL_PATH = os.path.join(MODEL_DIR, MODEL_FILENAME)
VECTOR_DB_DIR = "vectordb_phi3"

# PDF kontrolÃ¼
POSSIBLE_PDF_PATHS = ["nutuk.pdf", "pdfs/nutuk.pdf"]
PDF_PATH = None
for path in POSSIBLE_PDF_PATHS:
    if os.path.exists(path):
        PDF_PATH = path
        break

if not PDF_PATH:
    logger.error("âŒ 'nutuk.pdf' bulunamadÄ±. LÃ¼tfen dosyayÄ± bu dizine veya 'pdfs/' klasÃ¶rÃ¼ne ekleyin.")
    sys.exit(1)

def download_model():
    """Phi-3 Mini GGUF modeli mevcut deÄŸilse indirir."""
    if not os.path.exists(MODEL_PATH):
        logger.info(f"â¬‡ï¸ {MODEL_FILENAME} indiriliyor...")
        os.makedirs(MODEL_DIR, exist_ok=True)
        hf_hub_download(repo_id=MODEL_REPO, filename=MODEL_FILENAME, local_dir=MODEL_DIR)
        logger.info("âœ… Model indirildi.")
    else:
        logger.info("âœ… Model zaten mevcut.")

def setup_rag():
    """PDF'i iÅŸler, embedding'leri oluÅŸturur ve RAG zincirini kurar."""
    
    # 1. PDF YÃ¼kle
    logger.info(f"ğŸ“„ PDF yÃ¼kleniyor: {PDF_PATH}")
    loader = PyPDFLoader(PDF_PATH)
    documents = loader.load()
    logger.info(f"   {len(documents)} sayfa yÃ¼klendi.")

    # 2. Metni ParÃ§ala
    logger.info("âœ‚ï¸ Metin parÃ§alanÄ±yor...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)
    logger.info(f"   {len(texts)} parÃ§a oluÅŸturuldu.")

    # 3. Embedding'leri OluÅŸtur
    logger.info("ğŸ§  Embedding modeli yÃ¼kleniyor (all-MiniLM-L6-v2)...")
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    # 4. VektÃ¶r VeritabanÄ±
    logger.info("ğŸ’¾ VektÃ¶r veritabanÄ± oluÅŸturuluyor (ChromaDB)...")
    # VeritabanÄ± zaten varsa yÃ¼kle? Basitlik adÄ±na yeniden oluÅŸturuyoruz veya yÃ¼klÃ¼yoruz.
    # Chroma, persist_directory ayarlandÄ±ysa kalÄ±cÄ±lÄ±ÄŸÄ± yÃ¶netir.
    db = Chroma.from_documents(texts, embeddings, persist_directory=VECTOR_DB_DIR)
    
    # 5. LLM YÃ¼kle
    logger.info("ğŸ¤– Phi-3 Mini modeli yÃ¼kleniyor...")
    llm = LlamaCpp(
        model_path=MODEL_PATH,
        temperature=0.1,
        max_tokens=512,
        n_ctx=4096, # Phi-3 baÄŸlam penceresi
        verbose=False
    )

    # 6. QA Zincirini Kur
    # Phi-3 Talimat Ä°stemi Åablonu
    template = """<|user|>
AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak soruyu cevapla. CevabÄ± bilmiyorsan bilmiyorum de.

BaÄŸlam:
{context}

Soru:
{question}
<|end|>
<|assistant|>
"""
    prompt = PromptTemplate(template=template, input_variables=["context", "question"])

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )
    
    return qa

def main():
    print("ğŸš€ Nutuk RAG Sistemi BaÅŸlatÄ±lÄ±yor...")
    download_model()
    
    qa_chain = setup_rag()
    
    print("\nâœ… Sistem hazÄ±r! Nutuk hakkÄ±nda sorular sorabilirsiniz. (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q' veya 'exit')")
    print("-" * 50)
    
    while True:
        try:
            query = input("\nSoru: ").strip()
            if not query:
                continue
            if query.lower() in ['q', 'exit', 'quit']:
                print("ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
                break
            
            print("â³ DÃ¼ÅŸÃ¼nÃ¼yor...")
            res = qa_chain.invoke({"query": query})
            answer = res['result']
            
            print(f"\nğŸ¤– Cevap: {answer}")
            
            # KaynaklarÄ± gÃ¶rmek iÃ§in yorumu kaldÄ±rÄ±n
            # print("\nKaynaklar:")
            # for doc in res['source_documents']:
            #     print(f"- Sayfa {doc.metadata.get('page', '?')}: {doc.page_content[:100]}...")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Ä°ÅŸlem iptal edildi.")
            break
        except Exception as e:
            logger.error(f"Bir hata oluÅŸtu: {e}")

if __name__ == "__main__":
    main()
