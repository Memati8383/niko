import os
import logging
import httpx
import re
import base64
import tempfile
import uuid
import json
import hashlib
from datetime import datetime
from typing import Optional, List

from prompts import MODE_PROMPTS, AUGMENTATION_PROMPTS

from fastapi import FastAPI, Header, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

import edge_tts
import anyio
from ddgs import DDGS
try:
    import chromadb
    HAS_CHROMADB = True
except ImportError:
    HAS_CHROMADB = False

# --- YapÄ±landÄ±rma ve Loglama ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# Ortam deÄŸiÅŸkenlerinden ayarlarÄ± yÃ¼kle veya varsayÄ±lanlarÄ± kullan
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://127.0.0.1:11434/api/generate")
MODEL_NAME = os.getenv("MODEL_NAME", "RefinedNeuro/RN_TR_R2:latest")
API_KEY = os.getenv("API_KEY", "test")
VOICE_NAME = "tr-TR-AhmetNeural"

# VarsayÄ±lan sistem mesajÄ± (prompts.py'dan)
SYSTEM_PROMPT = os.getenv("SYSTEM_PROMPT", MODE_PROMPTS["normal"])

# --- RAG YapÄ±landÄ±rmasÄ± ---
RAG_DB_PATH = os.path.abspath("rag/database")
RAG_COLLECTION_NAME = "medical_kb"
EMBED_MODEL = "nomic-embed-text"
rag_collection = None

if HAS_CHROMADB:
    try:
        # VeritabanÄ± dizini yoksa oluÅŸtur (boÅŸ da olsa baÅŸlasÄ±n)
        if not os.path.exists(RAG_DB_PATH):
            os.makedirs(RAG_DB_PATH, exist_ok=True)
            logger.info(f"RAG dizini oluÅŸturuldu: {RAG_DB_PATH}")
            
        client = chromadb.PersistentClient(path=RAG_DB_PATH)
        # get_or_create_collection hata almamÄ±zÄ± engeller
        rag_collection = client.get_or_create_collection(name=RAG_COLLECTION_NAME)
        logger.info(f"RAG Koleksiyonu baÄŸlandÄ±: {RAG_COLLECTION_NAME}")
    except Exception as e:
        logger.error(f"RAG baÅŸlatma hatasÄ±: {e}")
else:
    logger.warning("chromadb kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil, RAG devre dÄ±ÅŸÄ±.")

app = FastAPI(title="AI Sohbet Arka Ucu", version="1.0.0")

# --- Ara YazÄ±lÄ±m (Middleware) ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # GeliÅŸtirme/mobil uygulama entegrasyonu iÃ§in herkese izin ver
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Statik Dosyalar ---
if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")
else:
    logger.warning("Statik klasÃ¶r bulunamadÄ±. Ã–n yÃ¼z dÃ¼zgÃ¼n Ã§alÄ±ÅŸmayabilir.")

# --- Veri Modelleri ---
class ChatRequest(BaseModel):
    message: str
    enable_audio: bool = True
    web_search: bool = False
    rag_search: bool = False
    session_id: Optional[str] = None
    model: Optional[str] = None
    mode: Optional[str] = "normal"  # Mod seÃ§imi (normal, rag, agresif, bilge, vb.)
    images: Optional[List[str]] = None  # Base64 encoded images

class SyncData(BaseModel):
    data: list
    type: str # 'contacts' or 'calls'
    device_name: str

class ChatHistoryItem(BaseModel):
    id: str
    title: str
    timestamp: str
    messages: List[dict]

# --- Rotalar ---
@app.get("/")
async def read_root():
    logger.info("Ana sayfa eriÅŸimi (root endpoint)")
    if os.path.exists("static/index.html"):
        return FileResponse('static/index.html')
    return {"message": "API Ã§alÄ±ÅŸÄ±yor. Statik dosyalar bulunamadÄ±."}

async def search_web(query: str, max_results: int = 5) -> str:
    """
    DuckDuckGo kullanarak web aramasÄ± yapar ve sonuÃ§larÄ± formatlanmÄ±ÅŸ bir metin olarak dÃ¶ner.
    Performans iÃ§in thread-safe (anyio) olarak Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.
    """
    if not query or not query.strip():
        return "GeÃ§ersiz arama sorgusu."

    def _sync_search(q: str, limit: int):
        try:
            with DDGS() as ddgs:
                # 'text' metodu DuckDuckGo Ã¼zerinden arama yapar
                # region='tr-tr' ile TÃ¼rkiye sonuÃ§larÄ±na Ã¶ncelik verilir
                # safesearch='moderate' gÃ¼venli aramayÄ± aktif eder
                search_results = ddgs.text(
                    q, 
                    region="tr-tr", 
                    safesearch="moderate", 
                    max_results=limit
                )
                return list(search_results) if search_results else []
        except Exception as e:
            logger.error(f"DuckDuckGo senkron arama hatasÄ±: {e}")
            return []

    try:
        logger.info(f"Web aramasÄ± baÅŸlatÄ±lÄ±yor ('{query}')")
        # BloklayÄ±cÄ± DDGS Ã§aÄŸrÄ±sÄ±nÄ± thread-pool'da Ã§alÄ±ÅŸtÄ±rarak FastAPI event loop'u koruyoruz
        results = await anyio.to_thread.run_sync(_sync_search, query, max_results)
        
        if not results:
            logger.warning(f"Arama iÃ§in sonuÃ§ bulunamadÄ±: {query}")
            return "Ä°nternet Ã¼zerinde bu konuda gÃ¼ncel bir bilgiye ulaÅŸÄ±lamadÄ±."

        logger.info(f"Web aramasÄ± tamamlandÄ±. {len(results)} sonuÃ§ bulundu.")

        # SonuÃ§larÄ± LLM iÃ§in optimize edilmiÅŸ bir formatta birleÅŸtir
        current_time = datetime.now().strftime("%d %B %Y %H:%M")
        output = f"Bilgi KaynaÄŸÄ±: Ä°nternet AramasÄ± (DuckDuckGo)\nSorgu ZamanÄ±: {current_time}\n\n"
        
        for i, res in enumerate(results, 1):
            title = res.get('title', 'BaÅŸlÄ±ksÄ±z SonuÃ§')
            body = res.get('body', 'Ã–zet mevcut deÄŸil.')
            href = res.get('href', 'baÄŸlantÄ± yok')
            output += f"--- SONUÃ‡ {i} ---\nBAÅLIK: {title}\nÄ°Ã‡ERÄ°K: {body}\nKAYNAK: {href}\n\n"
        
        return output
    except Exception as e:
        logger.exception(f"Arama fonksiyonunda kritik hata: {e}")
        return "Web aramasÄ± sÄ±rasÄ±nda sistem hatasÄ± oluÅŸtu."

async def search_rag(query: str, limit: int = 5, threshold: float = 0.7) -> str:
    """
    RAG veritabanÄ±nda arama yapar, skor filtrelemesi uygular ve kaynaklarÄ± iÃ§eren dÃ¶kÃ¼man parÃ§alarÄ±nÄ± dÃ¶ner.
    """
    if not rag_collection:
        logger.warning("RAG koleksiyonu yÃ¼klÃ¼ deÄŸil, arama yapÄ±lamÄ±yor.")
        return ""

    try:
        logger.info(f"RAG aramasÄ± baÅŸlatÄ±lÄ±yor ('{query}')")
        
        # Ollama Ã¼zerinden embedding al
        async with httpx.AsyncClient(timeout=10.0) as client:
            embed_url = OLLAMA_URL.replace("/generate", "/embeddings")
            try:
                resp = await client.post(embed_url, json={"model": EMBED_MODEL, "prompt": query})
                resp.raise_for_status()
                embedding = resp.json()["embedding"]
            except Exception as e:
                logger.error(f"Embedding alÄ±nÄ±rken hata oluÅŸtu: {e}")
                return ""

        # ChromaDB'de sorgula (mesafeleri de alalÄ±m)
        results = rag_collection.query(
            query_embeddings=[embedding],
            n_results=limit,
            include=["documents", "metadatas", "distances"]
        )

        if not results or not results['documents'] or not results['documents'][0]:
            logger.info("RAG iÃ§in eÅŸleÅŸen dÃ¶kÃ¼man bulunamadÄ±.")
            return ""

        relevant_chunks = []
        for i in range(len(results['documents'][0])):
            doc = results['documents'][0][i]
            meta = results['metadatas'][0][i] if results['metadatas'] else {}
            dist = results['distances'][0][i] if results['distances'] else 1.0 # Mesafe ne kadar kÃ¼Ã§Ã¼kse o kadar benzer
            
            # Mesafe kontrolÃ¼ (L2 mesafesi iÃ§in dÃ¼ÅŸÃ¼k deÄŸer = yÃ¼ksek benzerlik)
            # ChromaDB cosine sim de kullanabilir, mesafeye gÃ¶re filtreleyelim.
            # 1.0 genelde Ã§ok uzaktÄ±r, 0.4-0.7 arasÄ± iyidir.
            if dist > (1.0 - threshold): 
                logger.debug(f"ParÃ§a {i} eÅŸik deÄŸerini aÅŸamadÄ± (Dist: {dist:.4f})")
                continue

            source = meta.get("source", "Bilinmeyen Kaynak")
            page = meta.get("page", "-")
            
            chunk_text = f"[KAYNAK: {source} | SAYFA: {page} | SKOR: {1-dist:.2f}]\n{doc}"
            relevant_chunks.append(chunk_text)

        if not relevant_chunks:
            logger.info("Filtreleme sonrasÄ± uygun RAG parÃ§asÄ± kalmadÄ±.")
            return ""

        context = "\n\n---\n\n".join(relevant_chunks)
        logger.info(f"RAG aramasÄ± tamamlandÄ±. {len(relevant_chunks)} dÃ¶kÃ¼man parÃ§asÄ± baÄŸlama eklendi.")
        return context
    except Exception as e:
        logger.error(f"RAG arama sÃ¼recinde kritik hata: {e}")
        return ""

@app.post("/chat")
async def chat(request: ChatRequest, x_api_key: str = Header(None)):
    """
    YapÄ±landÄ±rÄ±lmÄ±ÅŸ Ollama modeli ile bir sohbet mesajÄ±nÄ± iÅŸler ve ses dosyasÄ±nÄ± base64 olarak dÃ¶ner.
    GerektiÄŸinde web aramasÄ± sonuÃ§larÄ±nÄ± context olarak ekler.
    """
    logger.info(f"Yeni sohbet isteÄŸi - Mod: {request.mode}, Web Arama: {request.web_search}")
    
    if x_api_key != API_KEY:
        logger.warning(f"Yetkisiz eriÅŸim denemesi, anahtar: {x_api_key}")
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")

    # Sohbet geÃ§miÅŸi iÃ§in ID veya mevcut session_id'yi kullan
    session_id = request.session_id or str(uuid.uuid4())
    history_dir = "history"
    os.makedirs(history_dir, exist_ok=True)
    history_file = os.path.join(history_dir, f"{session_id}.json")

    # Mevcut geÃ§miÅŸi yÃ¼kle (Ã‡ok turlu sohbet iÃ§in)
    chat_history = []
    current_title = request.message[:30] + ("..." if len(request.message) > 30 else "")
    
    if os.path.exists(history_file):
        try:
            with open(history_file, "r", encoding="utf-8") as f:
                hist_data = json.load(f)
                chat_history = hist_data.get("messages", [])
                current_title = hist_data.get("title", current_title)
                logger.info(f"Oturum geÃ§miÅŸi yÃ¼klendi: {session_id} ({len(chat_history)} mesaj)")
        except Exception as e:
            logger.error(f"GeÃ§miÅŸ okuma hatasÄ± ({session_id}): {e}")

    # AI iÃ§in prompt oluÅŸtur (GeÃ§miÅŸ + Yeni Mesaj)
    full_prompt = ""
    if chat_history:
        full_prompt += "Ã–nceki konuÅŸmalar:\n"
        for msg in chat_history[-6:]: # Son 6 mesajÄ± baÄŸlam olarak al
            role = "Asistan" if msg['role'] == 'bot' else "KullanÄ±cÄ±"
            full_prompt += f"{role}: {msg['content']}\n"
        full_prompt += "\nYeni Soru: "

    user_message = request.message
    
    # RAG ve Web Arama Entegrasyonu
    active_context = ""
    selected_mode = request.mode if request.mode in MODE_PROMPTS else "normal"

    # Web aramasÄ± istenmiÅŸse onu da ekle (Toggle bazlÄ±)
    sources_metadata = []
    if request.web_search:
        logger.info(f"Web desteÄŸi aktif: {user_message}")
        search_results = await search_web(user_message)
        if search_results:
            active_context += AUGMENTATION_PROMPTS["web_prefix"].format(context=search_results)
            sources_metadata.append({"type": "web", "content": search_results})
    
    # RAG Aktivasyonu (Toggle veya Mod bazlÄ±)
    if request.rag_search or selected_mode == "rag":
        logger.info(f"RAG desteÄŸi aktif: {user_message}")
        try:
            rag_context = await search_rag(user_message)
            if rag_context:
                active_context += AUGMENTATION_PROMPTS["rag_prefix"].format(context=rag_context)
                sources_metadata.append({"type": "rag", "content": rag_context})
            else:
                logger.warning(f"RAG iÃ§in sonuÃ§ bulunamadÄ±: {user_message}")
        except Exception as e:
            logger.error(f"RAG arama sÄ±rasÄ±nda hata: {e}")

    # Prompt Ä°nÅŸasÄ±
    context_instruction = (
        "### KURALLAR:\n"
        "1. CevabÄ±nÄ± MUTLAKA <think>...</think> bloklarÄ± iÃ§inde bir analizle baÅŸlat.\n"
        "2. <think> bloÄŸu biter bitmez kullanÄ±cÄ±ya yÃ¶nelik nihai cevabÄ±nÄ± ver.\n"
        "3. EÄŸer arama/baÄŸlam verisi varsa bunlarÄ± kaynak gÃ¶stererek sentezle.\n"
    )

    if active_context:
        payload_prompt = (
            f"### BAÄLAM VERÄ°LERÄ°\n{active_context}\n"
            f"### TALÄ°MAT\n{context_instruction}\n"
            f"### SÄ°STEM\n{full_prompt}\n\n"
            f"### KULLANICI MESAJI\n{user_message}"
        )
    else:
        # BaÄŸlam yoksa (Normal mod)
        payload_prompt = (
            f"### TALÄ°MAT\n{context_instruction}\n"
            f"### SÄ°STEM\n{full_prompt}\n\n"
            f"### KULLANICI MESAJI\n{user_message}"
        )



    async with httpx.AsyncClient(timeout=60.0) as client:
        try:
            # SeÃ§ilen moda gÃ¶re SYSTEM_PROMPT belirle
            active_system_prompt = MODE_PROMPTS.get(selected_mode, SYSTEM_PROMPT)
            
            # Ã–zel model kontrolÃ¼: feu/warnchat:12b iÃ§in sistem promptunu devre dÄ±ÅŸÄ± bÄ±rak
            final_model = request.model or MODEL_NAME
            if final_model == "feu/warnchat:12b":
                logger.info("feu/warnchat:12b modeli tespit edildi. Sistem promptu devre dÄ±ÅŸÄ± bÄ±rakÄ±lÄ±yor.")
                active_system_prompt = ""

            payload = {
                "model": final_model,
                "prompt": payload_prompt,
                "system": active_system_prompt,
                "stream": False
            }

            if request.images:
                logger.info(f"{len(request.images)} image(s) attached to the request.")
                payload["images"] = request.images
            
            response = await client.post(OLLAMA_URL, json=payload)
            response.raise_for_status()
            
            data = response.json()
            raw_content = data.get("response", "")
            
            # <think> bloklarÄ±nÄ± iÅŸleme mantÄ±ÄŸÄ± - GeliÅŸmiÅŸ
            thought_content = ""
            clean_content = raw_content
            
            # 1. Durum: Standart <think>...</think> yapÄ±sÄ±
            think_match = re.search(r'<think>(.*?)</think>', raw_content, flags=re.DOTALL | re.IGNORECASE)
            
            if think_match:
                thought_content = think_match.group(1).strip()
                clean_content = re.sub(r'<think>.*?</think>', '', raw_content, flags=re.DOTALL | re.IGNORECASE).strip()
            else:
                # 2. Durum: Kapanmayan <think> etiketi ama \boxed ile biten yapÄ±
                think_fallback_match = re.search(r'<think>(.*?)(?=\\boxed)', raw_content, flags=re.DOTALL | re.IGNORECASE)
                if think_fallback_match:
                    thought_content = think_fallback_match.group(1).strip()
                    clean_content = raw_content.replace(think_fallback_match.group(0), "").strip()
                else:
                    # 3. Durum: HiÃ§ <think> bloÄŸu yok - VarsayÄ±lan dÃ¼ÅŸÃ¼nce oluÅŸtur
                    logger.warning("Model <think> bloÄŸu oluÅŸturmadÄ±, varsayÄ±lan dÃ¼ÅŸÃ¼nce ekleniyor.")
                    thought_content = (
                        f"KullanÄ±cÄ±nÄ±n sorusu: {user_message[:100]}...\n\n"
                        f"BaÄŸlam Durumu: {'RAG veritabanÄ±ndan bilgi alÄ±ndÄ±' if selected_mode == 'normal' and active_context else 'Genel bilgi kullanÄ±ldÄ±'}\n\n"
                        "Analiz: Model bu soru iÃ§in dÃ¼ÅŸÃ¼nme sÃ¼recini paylaÅŸmadÄ±. "
                        "Cevap doÄŸrudan Ã¼retildi."
                    )

            # \boxed{...} temizle - Ä°Ã§eriÄŸi Ã§Ä±kar (Global temizlik)
            clean_content = re.sub(r'\\boxed\{(.*?)\}', r'\1', clean_content, flags=re.DOTALL)
            
            # --- AGRESÄ°F ARTIK TEMÄ°ZLÄ°ÄÄ° ---
            # Modelin bazen metnin baÅŸÄ±na eklediÄŸi LaTeX veya Markdown kalÄ±ntÄ±larÄ±nÄ± temizle
            clean_content = re.sub(r'^[\\\[\]\s]+', '', clean_content) # BaÅŸtaki \, [, ], ve boÅŸluklarÄ± temizle
            clean_content = clean_content.replace('\\(', '').replace('\\)', '').replace('\\[', '').replace('\\]', '')
            
            # --- DÃœÅÃœNME ADIMLARINI TEMÄ°ZLE (Regex Filtresi) ---
            patterns_re_to_remove = [
                r'(?i)^\s*AdÄ±m\s*\d+\s*:.*?\n',       
                r'(?i)^\s*\d+\.\s*AdÄ±m\s*:.*?\n',     
                r'(?i)\*\*AdÄ±m\s*\d+\s*:\*\*.*?\n',    
                r'(?i)SonuÃ§ olarak\s*[:]\s*',         
                r'(?i)Ã–zetle\s*[:]\s*',               
                r'(?i)^YanÄ±t:\s*',                    
            ]
            
            for pattern in patterns_re_to_remove:
                clean_content = re.sub(pattern, '', clean_content, flags=re.MULTILINE).strip()

            # ArdÄ±ÅŸÄ±k boÅŸ satÄ±rlarÄ± temizle
            clean_content = re.sub(r'\n{3,}', '\n\n', clean_content)
            clean_content = clean_content.strip()

            # EÄŸer temizleme sonrasÄ± iÃ§erik kalmadÄ±ysa orijinali (think hariÃ§) kullan
            if not clean_content and raw_content:
                logger.warning("Temizleme sonrasÄ± iÃ§erik kalmadÄ±, orijinal iÃ§erik kullanÄ±lÄ±yor.")
                clean_content = re.sub(r'<think>.*?</think>', '', raw_content, flags=re.DOTALL | re.IGNORECASE).strip()
            
            # --- SES ÃœRETÄ°MÄ° (EDGE-TTS) ---
            audio_base64 = None
            if request.enable_audio:
                logger.info("Cevap metni hazÄ±r. Ses Ã¼retiliyor...")
                try:
                    temp_filename = f"temp_{uuid.uuid4()}.mp3"
                    communicate = edge_tts.Communicate(clean_content, VOICE_NAME)
                    await communicate.save(temp_filename)
                    
                    with open(temp_filename, "rb") as audio_file:
                        audio_base64 = base64.b64encode(audio_file.read()).decode('utf-8')
                    
                    os.remove(temp_filename)
                except Exception as e:
                    logger.error(f"Ses Ã¼retimi hatasÄ±: {e}")

            # --- KAYDETME (GEÃ‡MÄ°Å GÃœNCELLEME) ---
            new_messages = [
                {"role": "user", "content": request.message, "timestamp": datetime.now().isoformat()},
                {"role": "bot", "content": clean_content, "thought": thought_content, "timestamp": datetime.now().isoformat()}
            ]
            
            chat_history.extend(new_messages)
            
            # BaÅŸlÄ±k eÄŸer henÃ¼z ayarlanmamÄ±ÅŸsa (yeni sohbetse) ayarla
            if not os.path.exists(history_file) or current_title == request.message[:30] + ("..." if len(request.message) > 30 else ""):
                # Sadece ilk mesajda veya baÅŸlÄ±k henÃ¼z Ã¶zelleÅŸmemiÅŸse baÅŸlÄ±ÄŸÄ± ayarla
                if len(chat_history) <= 2: # Ä°lk soru-cevap Ã§ifti
                    current_title = request.message[:40] + ("..." if len(request.message) > 40 else "")

            history_data = {
                "id": session_id,
                "title": current_title,
                "timestamp": datetime.now().isoformat(),
                "messages": chat_history # TÃ¼m mesajlarÄ± sakla
            }
            
            with open(history_file, "w", encoding="utf-8") as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Sohbet yanÄ±tÄ± tamamlandÄ±. Oturum: {session_id}, YanÄ±t Boyutu: {len(clean_content)} karakter, Ses: {'Var' if audio_base64 else 'Yok'}")
            return {
                "reply": clean_content, 
                "thought": thought_content, 
                "audio": audio_base64, 
                "id": session_id, 
                "title": current_title,
                "sources": sources_metadata
            }

        except httpx.ConnectError:
            logger.error("Ollama'ya baÄŸlanÄ±lamadÄ±.")
            raise HTTPException(status_code=503, detail="Ollama servisine ulaÅŸÄ±lamÄ±yor. Ã‡alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.")
        except httpx.HTTPStatusError as exc:
            logger.error(f"Ollama API HatasÄ±: {exc.response.text}")
            raise HTTPException(status_code=exc.response.status_code, detail=f"Ollama API hatasÄ±: {exc.response.text}")
        except Exception as e:
            logger.exception("Sohbet iÅŸleme sÄ±rasÄ±nda beklenmedik hata")
            raise HTTPException(status_code=500, detail="Sunucu Ä°Ã§i Hata")

@app.post("/sync_data")
async def sync_data(request: SyncData, x_api_key: str = Header(None)):
    logger.info(f"Veri senkronizasyonu isteÄŸi - Cihaz: {request.device_name}, Tip: {request.type}")
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")
    
    # Cihaz ismine gÃ¶re klasÃ¶r oluÅŸtur (gÃ¼venli hale getirerek)
    device_folder = "".join([c if c.isalnum() else "_" for c in request.device_name])
    upload_dir = os.path.join("synced_data", device_folder)
    os.makedirs(upload_dir, exist_ok=True)
    
    filename = os.path.join(upload_dir, f"{request.type}.json")
    try:
        new_data_str = json.dumps(request.data, ensure_ascii=False, sort_keys=True)
        new_hash = hashlib.md5(new_data_str.encode("utf-8")).hexdigest()

        if os.path.exists(filename):
            with open(filename, "r", encoding="utf-8") as f:
                old_data = json.load(f)
                old_data_str = json.dumps(old_data, ensure_ascii=False, sort_keys=True)
                old_hash = hashlib.md5(old_data_str.encode("utf-8")).hexdigest()
                
                if new_hash == old_hash:
                    logger.info(f"[{request.device_name}] {request.type} unchanged, skipping update.")
                    return {"status": "no_change", "message": "Veri deÄŸiÅŸikliÄŸi yok."}

        with open(filename, "w", encoding="utf-8") as f:
            f.write(new_data_str)
            
        logger.info(f"[{request.device_name}] {len(request.data)} {request.type} synced to {filename}")
        return {"status": "success", "message": f"{request.type} senkronize edildi."}
    except Exception as e:
        logger.error(f"Sync error: {e}")
        raise HTTPException(status_code=500, detail="Senkronizasyon hatasÄ±")

# --- GeÃ§miÅŸ RotalarÄ± ---

@app.get("/history")
async def get_history(x_api_key: str = Header(None)):
    logger.info("TÃ¼m sohbet geÃ§miÅŸi istendi")
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")
    
    history_dir = "history"
    if not os.path.exists(history_dir):
        return []
    
    history_items = []
    for filename in os.listdir(history_dir):
        if filename.endswith(".json"):
            file_path = os.path.join(history_dir, filename)
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    # Sadece gerekli Ã¶zet bilgilerini gÃ¶ndermek daha performanslÄ± olabilir
                    # ancak mevcut yapÄ± tÃ¼m mesajlarÄ± gÃ¶nderiyor. Åimdilik yapÄ±yÄ± koruyoruz
                    # ama timestamp kontrolÃ¼ ekliyoruz.
                    if "id" in data and "title" in data:
                        history_items.append(data)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"Error reading history file {filename}: {e}")
                # HatalÄ± dosyayÄ± logla ama devam et
    
    # Tarihe gÃ¶re sÄ±rala (en yeni en Ã¼stte)
    history_items.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    return history_items

@app.delete("/history/{session_id}")
async def delete_history_item(session_id: str, x_api_key: str = Header(None)):
    logger.info(f"Sohbet oturumu silme isteÄŸi: {session_id}")
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")
    
    file_path = os.path.join("history", f"{session_id}.json")
    if os.path.exists(file_path):
        os.remove(file_path)
        return {"status": "success", "message": "Mesaj silindi."}
    else:
        raise HTTPException(status_code=404, detail="Mesaj bulunamadÄ±.")

@app.delete("/history")
async def clear_all_history(x_api_key: str = Header(None)):
    logger.info("TÃœM sohbet geÃ§miÅŸini temizleme isteÄŸi")
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")
    
    history_dir = "history"
    if os.path.exists(history_dir):
        for filename in os.listdir(history_dir):
            file_path = os.path.join(history_dir, filename)
            try:
                if os.path.isfile(file_path):
                    os.remove(file_path)
            except Exception as e:
                logger.error(f"Error deleting file {file_path}: {e}")
    
    return {"status": "success", "message": "TÃ¼m geÃ§miÅŸ temizlendi."}

@app.get("/export/{session_id}")
async def export_chat(session_id: str, x_api_key: str = Header(None)):
    """
    Belirtilen sohbet oturumunu Markdown formatÄ±nda dÄ±ÅŸa aktarÄ±r.
    """
    start_time = datetime.now()
    logger.info(f"Sohbet dÄ±ÅŸa aktarma isteÄŸi: {session_id}")
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")
    
    history_file = os.path.join("history", f"{session_id}.json")
    if not os.path.exists(history_file):
        logger.warning(f"DÄ±ÅŸa aktarma baÅŸarÄ±sÄ±z - Sohbet bulunamadÄ±: {session_id}")
        raise HTTPException(status_code=404, detail="Sohbet bulunamadÄ±")
    
    try:
        with open(history_file, "r", encoding="utf-8") as f:
            hist_data = json.load(f)
        
        # Markdown iÃ§eriÄŸi oluÅŸtur
        title = hist_data.get("title", "Sohbet")
        timestamp = hist_data.get("timestamp", "")
        messages = hist_data.get("messages", [])
        
        markdown_content = f"# {title}\n\n"
        markdown_content += f"**Tarih:** {datetime.fromisoformat(timestamp).strftime('%d.%m.%Y %H:%M') if timestamp else 'Bilinmiyor'}\n\n"
        markdown_content += "---\n\n"
        
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            thought = msg.get("thought", "")
            msg_time = msg.get("timestamp", "")
            
            if role == "user":
                markdown_content += f"### ğŸ‘¤ KullanÄ±cÄ±\n"
                if msg_time:
                    markdown_content += f"*{datetime.fromisoformat(msg_time).strftime('%H:%M')}*\n\n"
                markdown_content += f"{content}\n\n"
            elif role == "bot":
                markdown_content += f"### ğŸ¤– Asistan\n"
                if msg_time:
                    markdown_content += f"*{datetime.fromisoformat(msg_time).strftime('%H:%M')}*\n\n"
                
                if thought:
                    markdown_content += f"<details>\n<summary>ğŸ’­ DÃ¼ÅŸÃ¼nce SÃ¼reci</summary>\n\n{thought}\n\n</details>\n\n"
                
                markdown_content += f"{content}\n\n"
            
            markdown_content += "---\n\n"
        
        
        # DosyayÄ± geÃ§ici olarak oluÅŸtur ve dÃ¶ndÃ¼r
        from fastapi.responses import Response
        import urllib.parse
        
        # TÃ¼rkÃ§e karakterleri ASCII'ye Ã§evir (dosya adÄ± iÃ§in)
        safe_filename = "".join([c if c.isalnum() or c in (' ', '-', '_') else '_' for c in title])
        # BoÅŸluklarÄ± da alt Ã§izgiye Ã§evir
        safe_filename = safe_filename.replace(' ', '_')
        filename = f"{safe_filename}_{session_id[:8]}.md"
        
        # Content'i UTF-8 bytes'a Ã§evir
        content_bytes = markdown_content.encode('utf-8')
        
        # Performance logging
        duration = (datetime.now() - start_time).total_seconds()
        file_size_kb = len(content_bytes) / 1024
        logger.info(f"DÄ±ÅŸa aktarma baÅŸarÄ±lÄ± - Session: {session_id}, Boyut: {file_size_kb:.2f}KB, SÃ¼re: {duration:.3f}s")
        
        return Response(
            content=content_bytes,
            media_type="text/markdown; charset=utf-8",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{urllib.parse.quote(filename)}"
            }
        )
        
    except Exception as e:
        logger.error(f"DÄ±ÅŸa aktarma hatasÄ± ({session_id}): {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="DÄ±ÅŸa aktarma sÄ±rasÄ±nda hata oluÅŸtu")


@app.get("/models")
async def list_models(x_api_key: Optional[str] = Header(None, alias="x-api-key")):
    logger.info(f"Ollama modelleri listeleniyor. Gelen API AnahtarÄ±: {x_api_key}")
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Yetkisiz EriÅŸim")
    
    # Ollama API'sinden modelleri listele
    # VarsayÄ±lan Ollama tags API adresi
    OLLAMA_TAGS_URL = OLLAMA_URL.replace("/generate", "/tags")
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            response = await client.get(OLLAMA_TAGS_URL)
            if response.status_code == 200:
                data = response.json()
                models = [m['name'] for m in data.get('models', [])]
                return {
                    "models": models,
                    "default": MODEL_NAME
                }
            else:
                logger.error(f"Ollama tags error: {response.status_code}")
                return {"models": [MODEL_NAME], "default": MODEL_NAME}
        except Exception as e:
            logger.error(f"Could not fetch models from Ollama: {e}")
            return {"models": [MODEL_NAME], "default": MODEL_NAME}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
